{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autofaiss getting started.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggE42ZFYxow6"
      },
      "source": [
        "# Information\n",
        "\n",
        "**This Demo notebook automatically creates a Faiss knn indices with the most optimal similarity search parameters.**\n",
        "\n",
        "It selects the best indexing parameters to achieve the highest recalls given memory and query speed constraints.\n",
        "\n",
        "Github: https://github.com/criteo/autofaiss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g-fxpx7187-"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "sqvufPhwySsS"
      },
      "source": [
        "#@title Index parameters\n",
        "\n",
        "max_index_query_time_ms = 10 #@param {type: \"number\"}\n",
        "max_index_memory_usage = \"10MB\" #@param\n",
        "metric_type = \"l2\" #@param ['ip', 'l2']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Rg7pm82Fml"
      },
      "source": [
        "# Embeddings creation (add your own embeddings here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRVmva4nEOGg"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = np.float32(np.random.rand(4000, 100))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lbqqSxFtI6n"
      },
      "source": [
        "# Save your embeddings on the disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUje1UcmF3-7"
      },
      "source": [
        "# Create a new folder\n",
        "import os\n",
        "import shutil\n",
        "embeddings_dir = \"embeddings_folder\"\n",
        "if os.path.exists(embeddings_dir):\n",
        "  shutil.rmtree(embeddings_dir)\n",
        "os.makedirs(embeddings_dir)\n",
        "\n",
        "# Save your embeddings\n",
        "# You can split you embeddings in several parts if it is too big\n",
        "# The data will be read in the lexicographical order of the filenames\n",
        "np.save(f\"{embeddings_dir}/part1.npy\", embeddings[:2000]) \n",
        "np.save(f\"{embeddings_dir}/part2.npy\", embeddings[2000:]) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7h7hl6VubLt"
      },
      "source": [
        "# Build the KNN index with Autofaiss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q0LDFu0p2-g"
      },
      "source": [
        "os.makedirs(\"my_index_folder\", exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vIqMP8zHTHO",
        "outputId": "0d6a830e-a33b-4595-d4b1-d5a5048c408e"
      },
      "source": [
        "# Install autofaiss\n",
        "!pip install autofaiss &> /dev/null\n",
        "\n",
        "# Build a KNN index\n",
        "!autofaiss quantize --embeddings_path={embeddings_dir} \\\n",
        "                    --output_path=\"my_index_folder\" \\\n",
        "                    --metric_type={metric_type} \\\n",
        "                    --max_index_query_time_ms=5 \\\n",
        "                    --max_index_memory_usage={max_index_memory_usage}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Launching the whole pipeline 08/02/2021, 13:25:58\n",
            "\tCompute estimated construction time of the index 08/02/2021, 13:25:58\n",
            "\t\t-> Train: 16.7 minutes\n",
            "\t\t-> Add: 0.0 seconds\n",
            "\t\tTotal: 16.7 minutes\n",
            "\t>>> Finished \"Compute estimated construction time of the index\" in 0.0001 secs\n",
            "\tChecking that your have enough memory available to create the index 08/02/2021, 13:25:58\n",
            "\t>>> Finished \"Checking that your have enough memory available to create the index\" in 0.0006 secs\n",
            "\tSelecting most promising index types given data characteristics 08/02/2021, 13:25:58\n",
            "\t>>> Finished \"Selecting most promising index types given data characteristics\" in 0.0012 secs\n",
            "\tCreating the index 08/02/2021, 13:25:58\n",
            "\t\t-> Instanciate the index HNSW32 08/02/2021, 13:25:58\n",
            "\t\t>>> Finished \"-> Instanciate the index HNSW32\" in 0.0013 secs\n",
            "\t\t-> Extract training vectors 08/02/2021, 13:25:58\n",
            "\r  0% 0/2 [00:00<?, ?it/s]\r100% 2/2 [00:00<00:00, 1055.97it/s]\n",
            "\t\t>>> Finished \"-> Extract training vectors\" in 0.0138 secs\n",
            "\t\t-> Training the index with 4000 vectors of dim 100 08/02/2021, 13:25:58\n",
            "\t\t>>> Finished \"-> Training the index with 4000 vectors of dim 100\" in 0.0001 secs\n",
            "\t\t-> Adding the vectors to the index 08/02/2021, 13:25:58\n",
            "100% 2/2 [00:00<00:00,  4.91it/s]\n",
            "\t\t>>> Finished \"-> Adding the vectors to the index\" in 1.7210 secs\n",
            "\t>>> Finished \"Creating the index\" in 1.7372 secs\n",
            "\tComputing best hyperparameters 08/02/2021, 13:26:00\n",
            "\t>>> Finished \"Computing best hyperparameters\" in 1.6057 secs\n",
            "The best hyperparameters are: efSearch=1319\n",
            "\tSaving the index on local disk 08/02/2021, 13:26:01\n",
            "\t>>> Finished \"Saving the index on local disk\" in 0.0027 secs\n",
            "\tCompute fast metrics 08/02/2021, 13:26:01\n",
            "2000\n",
            "\t>>> Finished \"Compute fast metrics\" in 9.8355 secs\n",
            "Recap:\n",
            "{'99p_search_speed_ms': 7.556187009999177,\n",
            " 'avg_search_speed_ms': 4.902101082999792,\n",
            " 'compression ratio': 0.5956986092671344,\n",
            " 'nb vectors': 4000,\n",
            " 'reconstruction error %': 0.0,\n",
            " 'size in bytes': 2685922,\n",
            " 'vectors dimension': 100}\n",
            ">>> Finished \"Launching the whole pipeline\" in 13.1962 secs\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk5PrzhRujjL"
      },
      "source": [
        "# Load the index and play with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPJg6O6Fsq7R",
        "outputId": "42e46393-e505-46be-b015-51a1797d471e"
      },
      "source": [
        "import faiss\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "my_index = faiss.read_index(glob.glob(\"my_index_folder/*.index\")[0])\n",
        "\n",
        "query_vector = np.float32(np.random.rand(1, 100))\n",
        "k = 5\n",
        "distances, indices = my_index.search(query_vector, k)\n",
        "\n",
        "print(f\"Top {k} elements in the dataset for max inner product search:\")\n",
        "for i, (dist, indice) in enumerate(zip(distances[0], indices[0])):\n",
        "  print(f\"{i+1}: Vector number {indice:4} with distance {dist}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 5 elements in the dataset for max inner product search:\n",
            "1: Vector number 2933 with distance 10.404068946838379\n",
            "2: Vector number  168 with distance 10.53512191772461\n",
            "3: Vector number 2475 with distance 10.688979148864746\n",
            "4: Vector number 2525 with distance 10.713528633117676\n",
            "5: Vector number 3463 with distance 10.774477005004883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cnt0_vAuw5z"
      },
      "source": [
        "# (Bonus) Python version of the CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXBVQpMXt3Y6",
        "outputId": "efb3326f-4b43-4e9f-8c25-31b5d1021fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        }
      },
      "source": [
        "from autofaiss.external.quantize import Quantizer\n",
        "\n",
        "quantizer = Quantizer()\n",
        "\n",
        "quantizer.quantize(embeddings_path=\"embeddings_folder\",\n",
        "                   output_path=\"my_index_folder\",\n",
        "                   max_index_query_time_ms = max_index_query_time_ms,\n",
        "                   max_index_memory_usage = max_index_memory_usage,\n",
        "                   metric_type=metric_type)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Launching the whole pipeline 08/02/2021, 13:26:11\n",
            "\tCompute estimated construction time of the index 08/02/2021, 13:26:11\n",
            "\t\t-> Train: 16.7 minutes\n",
            "\t\t-> Add: 0.0 seconds\n",
            "\t\tTotal: 16.7 minutes\n",
            "\t>>> Finished \"Compute estimated construction time of the index\" in 0.0007 secs\n",
            "\tChecking that your have enough memory available to create the index 08/02/2021, 13:26:11\n",
            "\t>>> Finished \"Checking that your have enough memory available to create the index\" in 0.0012 secs\n",
            "\tSelecting most promising index types given data characteristics 08/02/2021, 13:26:11\n",
            "\t>>> Finished \"Selecting most promising index types given data characteristics\" in 0.0043 secs\n",
            "\tCreating the index 08/02/2021, 13:26:11\n",
            "\t\t-> Instanciate the index HNSW32 08/02/2021, 13:26:11\n",
            "\t\t>>> Finished \"-> Instanciate the index HNSW32\" in 0.0021 secs\n",
            "\t\t-> Extract training vectors 08/02/2021, 13:26:11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 421.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\t>>> Finished \"-> Extract training vectors\" in 0.0238 secs\n",
            "\t\t-> Training the index with 4000 vectors of dim 100 08/02/2021, 13:26:11\n",
            "\t\t>>> Finished \"-> Training the index with 4000 vectors of dim 100\" in 0.0000 secs\n",
            "\t\t-> Adding the vectors to the index 08/02/2021, 13:26:11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\t>>> Finished \"-> Adding the vectors to the index\" in 1.7814 secs\n",
            "\t>>> Finished \"Creating the index\" in 1.8182 secs\n",
            "\tComputing best hyperparameters 08/02/2021, 13:26:13\n",
            "\t>>> Finished \"Computing best hyperparameters\" in 3.2071 secs\n",
            "The best hyperparameters are: efSearch=2077\n",
            "\tSaving the index on local disk 08/02/2021, 13:26:16\n",
            "\t>>> Finished \"Saving the index on local disk\" in 0.0064 secs\n",
            "\tCompute fast metrics 08/02/2021, 13:26:16\n",
            "1025\n",
            "\t>>> Finished \"Compute fast metrics\" in 10.0180 secs\n",
            "Recap:\n",
            "{'99p_search_speed_ms': 13.157404919996907,\n",
            " 'avg_search_speed_ms': 9.750819220487383,\n",
            " 'compression ratio': 0.5956986092671344,\n",
            " 'nb vectors': 4000,\n",
            " 'reconstruction error %': 0.0,\n",
            " 'size in bytes': 2685922,\n",
            " 'vectors dimension': 100}\n",
            ">>> Finished \"Launching the whole pipeline\" in 15.0867 secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Done'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX5Takvp35df"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
