<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Creating an index &mdash; autofaiss 1.0.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Python documentation" href="../API/api.html" />
    <link rel="prev" title="Introduction" href="../introduction/introduction.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> autofaiss
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction and installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/introduction.html#installing-the-requirements">Installing the requirements</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting started with the CLI</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Creating an index</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#the-use-case">The use-case</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-build-index-command">The build_index command</a></li>
<li class="toctree-l2"><a class="reference internal" href="#time-required">Time required</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#tuning-an-existing-index">Tuning an existing index</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">The use-case</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-tune-index-command">The tune_index command</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">Time required</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-it-does-behind">What it does behind</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#getting-scores-on-an-index">Getting scores on an index</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id3">The use-case</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-score-command">The score command</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id5">Time required</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#creating-partitioned-indexes">Creating partitioned indexes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id6">The use-case</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-build-partitioned-indexes-command">The build_partitioned_indexes command</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">What it does behind</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use autofaiss from python</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../API/api.html">Python documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_source/modules.html">autofaiss</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting started with notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/autofaiss_getting_started.html">Autofaiss getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/autofaiss_index_selection_demo.html">Autofaiss Index selection demo slider</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">autofaiss</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Creating an index</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/getting_started/quantization.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="creating-an-index">
<h1>Creating an index<a class="headerlink" href="#creating-an-index" title="Permalink to this heading"></a></h1>
<section id="the-use-case">
<h2>The use-case<a class="headerlink" href="#the-use-case" title="Permalink to this heading"></a></h2>
<p>You have limited RAM constraint but need to do similarity search on a lot of vectors?
Great! You are in the right place :) This lib automatically builds an optimal index that maximizes the
recall scores given a memory and query speed constraint.</p>
</section>
<section id="the-build-index-command">
<h2>The build_index command<a class="headerlink" href="#the-build-index-command" title="Permalink to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">autofaiss</span> <span class="pre">build_index</span></code> command takes the following parameters:</p>
<table class="colwidths-given docutils align-default" id="id8">
<caption><span class="caption-text">Parameters</span><a class="headerlink" href="#id8" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Flag available</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>–embeddings</p></td>
<td><p>required</p></td>
<td><p>Source path of the directory containing your .npy embedding files. If there are several files, they are read in the lexicographical order. This can be a local path or a path in another Filesystem e.g. <cite>hdfs://root/…</cite> or <cite>s3://…</cite></p></td>
</tr>
<tr class="row-odd"><td><p>–index_path</p></td>
<td><p>required</p></td>
<td><p>Destination path of the faiss index on local machine.</p></td>
</tr>
<tr class="row-even"><td><p>–index_infos_path</p></td>
<td><p>required</p></td>
<td><p>Destination path of the faiss index infos on local machine.</p></td>
</tr>
<tr class="row-odd"><td><p>–save_on_disk</p></td>
<td><p>required</p></td>
<td><p>Save the index on the disk.</p></td>
</tr>
<tr class="row-even"><td><p>–file_format</p></td>
<td><p>“npy”</p></td>
<td><p>File format of the files in embeddings. Can be either <cite>npy</cite> for numpy matrix files or <cite>parquet</cite> for parquet serialized tables</p></td>
</tr>
<tr class="row-odd"><td><p>–embedding_column_name</p></td>
<td><p>“embeddings”</p></td>
<td><p>Only necessary when file_format=`parquet` In this case this is the name of the column containing the embeddings (one vector per row)</p></td>
</tr>
<tr class="row-even"><td><p>–id_columns</p></td>
<td><p>None</p></td>
<td><p>Can only be used when file_format=`parquet`. In this case these are the names of the columns containing the Ids of the vectors, and separate files will be generated to map these ids to indices in the KNN index</p></td>
</tr>
<tr class="row-odd"><td><p>–ids_path</p></td>
<td><p>None</p></td>
<td><p>Only useful when id_columns is not None and file_format=`parquet`. This will be the path (in any filesystem) where the mapping files Ids-&gt;vector index will be store in parquet format</p></td>
</tr>
<tr class="row-even"><td><p>–metric_type</p></td>
<td><p>“ip”</p></td>
<td><p>(Optional) Similarity function used for query: (“ip” for inner product, “l2” for euclidian distance)</p></td>
</tr>
<tr class="row-odd"><td><p>–max_index_memory_usage</p></td>
<td><p>“32GB”</p></td>
<td><p>(Optional) Maximum size in GB of the created index, this bound is strict.</p></td>
</tr>
<tr class="row-even"><td><p>–current_memory_available</p></td>
<td><p>“32GB”</p></td>
<td><p>(Optional) Memory available (in GB) on the machine creating the index, having more memory is a boost because it reduces the swipe between RAM and disk.</p></td>
</tr>
<tr class="row-odd"><td><p>–max_index_query_time_ms</p></td>
<td><p>10</p></td>
<td><p>(Optional) Bound on the query time for KNN search, this bound is approximative.</p></td>
</tr>
<tr class="row-even"><td><p>–min_nearest_neighbors_to_retrieve</p></td>
<td><p>20</p></td>
<td><p>(Optional) Minimum number of nearest neighbors to retrieve when querying the index. Parameter used only during index hyperparameter finetuning step, it is not taken into account to select the indexing algorithm. This parameter has the priority over the max_index_query_time_ms constraint.</p></td>
</tr>
<tr class="row-odd"><td><p>–index_key</p></td>
<td><p>None</p></td>
<td><p>(Optional) If present, the Faiss index will be build using this description string in the index_factory, more detail in the [Faiss documentation](<a class="reference external" href="https://github.com/facebookresearch/faiss/wiki/The-index-factory">https://github.com/facebookresearch/faiss/wiki/The-index-factory</a>)</p></td>
</tr>
<tr class="row-even"><td><p>–index_param</p></td>
<td><p>None</p></td>
<td><p>(Optional) If present, the Faiss index will be set using this description string of hyperparameters, more detail in the [Faiss documentation](<a class="reference external" href="https://github.com/facebookresearch/faiss/wiki/Index-IO,-cloning-and-hyper-parameter-tuning">https://github.com/facebookresearch/faiss/wiki/Index-IO,-cloning-and-hyper-parameter-tuning</a>)</p></td>
</tr>
<tr class="row-odd"><td><p>–use_gpu</p></td>
<td><p>False</p></td>
<td><p>(Optional) Experimental, gpu training can be faster, but this feature is not tested so far.</p></td>
</tr>
<tr class="row-even"><td><p>–nb_cores</p></td>
<td><p>None</p></td>
<td><p>(Optional) The number of cores to use, by default will use all cores</p></td>
</tr>
<tr class="row-odd"><td><p>–make_direct_map</p></td>
<td><p>False</p></td>
<td><p>(Optional) If set to True and that the created index is an IVF, call .make_direct_map() on the index to build a mapping (stored on RAM only) that speeds up greatly the calls to .reconstruct().</p></td>
</tr>
<tr class="row-even"><td><p>–should_be_memory_mappable</p></td>
<td><p>False</p></td>
<td><p>(Optional) If set to true, the created index will be selected only among the indices that can be memory-mapped on disk. This makes it possible to use 50GB indices on a machine with only 1GB of RAM.</p></td>
</tr>
<tr class="row-odd"><td><p>–distributed</p></td>
<td><p>None</p></td>
<td><p>(Optional) If “pyspark”, create the index using pyspark. Otherwise, the index is created on your local machine.</p></td>
</tr>
<tr class="row-even"><td><p>–temporary_indices_folder</p></td>
<td><p>“hdfs://root/tmp/distributed_autofaiss_indices”</p></td>
<td><p>(Optional) Folder to save the temporary small indices, only used when distributed = “pyspark”</p></td>
</tr>
<tr class="row-odd"><td><p>–verbose</p></td>
<td><p>20</p></td>
<td><p>(Optional) Set verbosity of logging output: DEBUG=10, INFO=20, WARN=30, ERROR=40, CRITICAL=50</p></td>
</tr>
<tr class="row-even"><td><p>–nb_indices_to_keep</p></td>
<td><p>1</p></td>
<td><p>(Optional) Number of indices to keep at most when distributed is “pyspark”.</p></td>
</tr>
</tbody>
</table>
<p>The same function can be called directly from a python environment (from autofaiss import build_index).</p>
<p>It is possible to force the creation of a specific index with specific hyperparameters if more control is needed.
Here is some documentation &lt;<a class="reference external" href="https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index">https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index</a>&gt; and
&lt;<a class="reference external" href="https://github.com/facebookresearch/faiss/wiki/The-index-factory">https://github.com/facebookresearch/faiss/wiki/The-index-factory</a>&gt; to help you to choose which index you need.</p>
</section>
<section id="time-required">
<h2>Time required<a class="headerlink" href="#time-required" title="Permalink to this heading"></a></h2>
<p>The time required to run this command is:</p>
<ul class="simple">
<li><p>For 1TB of vectors -&gt; 2 hours</p></li>
<li><p>For 150GB of vectors -&gt; 1 hour</p></li>
<li><p>For 50GB of vectors -&gt; 20 minutes</p></li>
</ul>
</section>
</section>
<section id="tuning-an-existing-index">
<h1>Tuning an existing index<a class="headerlink" href="#tuning-an-existing-index" title="Permalink to this heading"></a></h1>
<section id="id1">
<h2>The use-case<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h2>
<p>You have already created a Faiss index but you would like to have a better recall/query-time ratio?
This command creates a new index with different hyperparameters to be closer to your requirements.</p>
</section>
<section id="the-tune-index-command">
<h2>The tune_index command<a class="headerlink" href="#the-tune-index-command" title="Permalink to this heading"></a></h2>
<p>The tune_index command set the hyperparameters for the given index.</p>
<p>If an index_param is given, set this hyperparameters to the index,
otherwise perform a greedy heusistic to make the best out or the max_index_query_time_ms constraint</p>
</section>
<section id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading"></a></h2>
<dl class="simple">
<dt>index_path<span class="classifier">Union[str, Any]</span></dt><dd><p>Path to .index file on local disk if is_local_index_path is True,
otherwise path on hdfs.
Can also be an index</p>
</dd>
<dt>index_key: str</dt><dd><p>String to give to the index factory in order to create the index.</p>
</dd>
<dt>index_param: Optional(str)</dt><dd><p>Optional string with hyperparameters to set to the index.
If None, the hyper-parameters are chosen based on an heuristic.</p>
</dd>
<dt>output_index_path: str</dt><dd><p>Path to the newly created .index file</p>
</dd>
<dt>save_on_disk: bool</dt><dd><p>Whether to save the index on disk, default to True.</p>
</dd>
<dt>min_nearest_neighbors_to_retrieve: int</dt><dd><p>Minimum number of nearest neighbors to retrieve when querying the index.</p>
</dd>
<dt>max_index_query_time_ms: float</dt><dd><p>Query speed constraint for the index to create.</p>
</dd>
<dt>use_gpu: bool</dt><dd><p>Experimental, gpu training is faster, not tested so far.</p>
</dd>
<dt>verbose: int</dt><dd><p>set verbosity of outputs via logging level, default is <cite>logging.INFO</cite></p>
</dd>
</dl>
</section>
<section id="returns">
<h2>Returns<a class="headerlink" href="#returns" title="Permalink to this heading"></a></h2>
<dl class="simple">
<dt>index</dt><dd><p>The faiss index</p>
</dd>
</dl>
</section>
<section id="id2">
<h2>Time required<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h2>
<p>The time required to run this command is around 1 minute.</p>
</section>
<section id="what-it-does-behind">
<h2>What it does behind<a class="headerlink" href="#what-it-does-behind" title="Permalink to this heading"></a></h2>
<p>The tuning only works for inverted index with HNSW on top of it (95% of indices created by the lib).
there are 3 parameters to tune for that index:</p>
<ul class="simple">
<li><p>nprobe:      The number of cells to visit, directly linked to query time (a cell contains on average nb_total_vectors/nb_clusters vectors)</p></li>
<li><p>efSearch:    Search parameter of the HNSW on top of the clusters centers. It has a small impact on search time.</p></li>
<li><p>ht:          The Hamming threshold, adds a boost in speed but reduces the recall.</p></li>
</ul>
<p>efSearch is set to be 2 times higher than nprobe, and the Hamming threshold is desactivated by setting it to a high value.</p>
<p>By doing so, we can optimize on only one dimension by applying a binary search given a query time constraint.</p>
</section>
</section>
<section id="getting-scores-on-an-index">
<h1>Getting scores on an index<a class="headerlink" href="#getting-scores-on-an-index" title="Permalink to this heading"></a></h1>
<section id="id3">
<h2>The use-case<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h2>
<p>You have a faiss index and you would like to know it’s 1-recall, intersection recall, query speed, …?
There is a command for that too, it’s the score command.</p>
</section>
<section id="the-score-command">
<h2>The score command<a class="headerlink" href="#the-score-command" title="Permalink to this heading"></a></h2>
<p>You just need the path to your index and the embeddings for this one.
Be careful, computing accurate metrics is slow.</p>
<p>Compute metrics on a given index, use cached ground truth for fast scoring the next times.</p>
<p><code class="docutils literal notranslate"><span class="pre">autofaiss</span> <span class="pre">score_index</span> <span class="pre">--embeddings=&quot;folder/embs&quot;</span> <span class="pre">--index_path=&quot;some.index&quot;</span> <span class="pre">--output_index_info_path</span> <span class="pre">&quot;infos.json&quot;</span> <span class="pre">--current_memory_available=&quot;4G&quot;</span></code></p>
</section>
<section id="id4">
<h2>Parameters<a class="headerlink" href="#id4" title="Permalink to this heading"></a></h2>
<dl class="simple">
<dt>index_path<span class="classifier">Union[str, Any]</span></dt><dd><p>Path to .index file. Or in memory index</p>
</dd>
<dt>embeddings: str</dt><dd><p>Local path containing all preprocessed vectors and cached files.</p>
</dd>
<dt>output_index_info_path<span class="classifier">str</span></dt><dd><p>Path to index infos .json</p>
</dd>
<dt>save_on_disk<span class="classifier">bool</span></dt><dd><p>Whether to save on disk</p>
</dd>
<dt>current_memory_available: str</dt><dd><p>Memory available on the current machine, having more memory is a boost
because it reduces the swipe between RAM and disk.</p>
</dd>
<dt>verbose: int</dt><dd><p>set verbosity of outputs via logging level, default is <cite>logging.INFO</cite></p>
</dd>
</dl>
</section>
<section id="id5">
<h2>Time required<a class="headerlink" href="#id5" title="Permalink to this heading"></a></h2>
<p>The time required to run this command is around 1 hour for 200M vectors of 1280d (1TB).
If the whole dataset fits in RAM it can be much faster.</p>
</section>
</section>
<section id="creating-partitioned-indexes">
<h1>Creating partitioned indexes<a class="headerlink" href="#creating-partitioned-indexes" title="Permalink to this heading"></a></h1>
<section id="id6">
<h2>The use-case<a class="headerlink" href="#id6" title="Permalink to this heading"></a></h2>
<p>You have a partitioned parquet dataset and want to create one index per partition.</p>
</section>
<section id="the-build-partitioned-indexes-command">
<h2>The build_partitioned_indexes command<a class="headerlink" href="#the-build-partitioned-indexes-command" title="Permalink to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">autofaiss</span> <span class="pre">build_partitioned_indexes</span></code> command takes the following parameters:</p>
<table class="colwidths-given docutils align-default" id="id9">
<caption><span class="caption-text">Parameters</span><a class="headerlink" href="#id9" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Flag available</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>–partitions</p></td>
<td><p>required</p></td>
<td><p>List of partitions containing embeddings. Paths can be local paths or paths in another Filesystem e.g. <cite>hdfs://root/…</cite> or <cite>s3://…</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p>–output_root_dir</p></td>
<td><p>required</p></td>
<td><p>Output root directory where indexes, metrics and ids will be written.</p></td>
</tr>
<tr class="row-even"><td><p>–embedding_column_name</p></td>
<td><p>“embedding”</p></td>
<td><p>Parquet dataset column name containing embeddings.</p></td>
</tr>
<tr class="row-odd"><td><p>–index_key</p></td>
<td><p>None</p></td>
<td><p>Optional string to give to the index factory in order to create the index. If None, an index is chosen based on an heuristic.</p></td>
</tr>
<tr class="row-even"><td><p>–id_columns</p></td>
<td><p>None</p></td>
<td><p>Parquet dataset column name(s) that are used as IDs for embeddings. A mapping from these IDs to faiss indices will be written in separate files.</p></td>
</tr>
<tr class="row-odd"><td><p>–max_index_query_time_ms</p></td>
<td><p>10</p></td>
<td><p>Bound on the query time for KNN search, this bound is approximative.</p></td>
</tr>
<tr class="row-even"><td><p>–max_index_memory_usage</p></td>
<td><p>16GB</p></td>
<td><p>Maximum size allowed for the index, this bound is strict.</p></td>
</tr>
<tr class="row-odd"><td><p>–min_nearest_neighbors_to_retrieve</p></td>
<td><p>20</p></td>
<td><p>Minimum number of nearest neighbors to retrieve when querying the index. Parameter used only during index hyperparameter finetuning step, it is not taken into account to select the indexing algorithm. This parameter has the priority over the max_index_query_time_ms constraint.</p></td>
</tr>
<tr class="row-even"><td><p>–current_memory_available</p></td>
<td><p>32GB</p></td>
<td><p>Memory available on the machine creating the index, having more memory is a boost because it reduces the swipe between RAM and disk.</p></td>
</tr>
<tr class="row-odd"><td><p>–use_gpu</p></td>
<td><p>False</p></td>
<td><p>Experimental, gpu training is faster, not tested so far.</p></td>
</tr>
<tr class="row-even"><td><p>–metric_type</p></td>
<td><p>ip</p></td>
<td><p>Similarity function used for query: “ip” for inner product or “l2” for euclidean distance.</p></td>
</tr>
<tr class="row-odd"><td><p>–nb_cores</p></td>
<td><p>None</p></td>
<td><p>Number of cores to use. Will try to guess the right number if not provided.</p></td>
</tr>
<tr class="row-even"><td><p>–make_direct_map</p></td>
<td><p>False</p></td>
<td><p>Create a direct map allowing reconstruction of embeddings. This is only needed for IVF indices. Note that might increase the RAM usage (approximately 8GB for 1 billion embeddings).</p></td>
</tr>
<tr class="row-odd"><td><p>–should_be_memory_mappable</p></td>
<td><p>False</p></td>
<td><p>If set to true, the created index will be selected only among the indices that can be memory-mapped on disk. This makes it possible to use 50GB indices on a machine with only 1GB of RAM. Default to False.</p></td>
</tr>
<tr class="row-even"><td><p>–temp_root_dir</p></td>
<td><p>“hdfs://root/tmp/distributed_autofaiss_indices”</p></td>
<td><p>Temporary directory that will be used to store intermediate results/computation.</p></td>
</tr>
<tr class="row-odd"><td><p>–verbose</p></td>
<td><p>logging.INFO</p></td>
<td><p>set verbosity of outputs via logging level, default is <cite>logging.INFO</cite>.</p></td>
</tr>
<tr class="row-even"><td><p>–nb_splits_per_big_index</p></td>
<td><p>1</p></td>
<td><p>Number of indices to split a big index into. This allows you building indices bigger than <cite>current_memory_available</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p>–big_index_threshold</p></td>
<td><p>5_000_000</p></td>
<td><p>Threshold used to define big indexes. Indexes with more <cite>than big_index_threshold</cite> embeddings are considered big indexes.</p></td>
</tr>
<tr class="row-even"><td><p>–maximum_nb_threads</p></td>
<td><p>256</p></td>
<td><p>Maximum number of threads to parallelize index creation.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id7">
<h2>What it does behind<a class="headerlink" href="#id7" title="Permalink to this heading"></a></h2>
<p>For each partition of the partitioned dataset, one index will be trained and populated with vectors of the partition.
All indexes are created in parallel. Also, for big partitions (with more than <cite>big_index_threshold</cite> vectors), vectors will be added in a distributed way to indexes.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../introduction/introduction.html" class="btn btn-neutral float-left" title="Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../API/api.html" class="btn btn-neutral float-right" title="Python documentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Criteo.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>